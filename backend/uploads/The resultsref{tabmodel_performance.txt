The results\ref{tab:model_performance} highlight that DenseNet201â€™s dense connectivity enables better gradient flow and feature reuse, leading to enhanced sequence prediction capabilities. Conversely, ResNet50's residual learning approach provides strong feature extraction but does not outperform DenseNet201 in this specific text generation task. The lower performance of VGG16+LSTM suggests that deeper and more optimized CNN architectures contribute significantly to improving alternate text generation quality.
